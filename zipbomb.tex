\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix2019_v3}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage{makecell}
\usepackage{pifont}
\usepackage{threeparttable}
\usepackage{xcolor}
\usepackage[binary-units,number-unit-product=~]{siunitx}

\urlstyle{same}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Section}
% Better look for citations that include a section reference like \cite[\S 3]{foobar}.
\renewcommand{\citemid}{~}

% Disable metadata for reproducible PDF.
% https://tex.stackexchange.com/a/313605
\ifpdf
\pdfinfoomitdate=1
\pdftrailerid{}
\pdfsuppressptexinfo=-1
\hypersetup{pdfcreator={},pdfproducer={}}
\fi

\newcommand{\kB}{\kilo\byte}
\newcommand{\MB}{\mega\byte}
\newcommand{\GB}{\giga\byte}
\newcommand{\TB}{\tera\byte}
\newcommand{\PB}{\peta\byte}
\newcommand{\EB}{\exa\byte}
\newcommand{\EiB}{\exbi\byte}

\newcommand{\CDH}{\mathrm{CDH}}
\newcommand{\LFH}{\mathrm{LFH}}
\newcommand{\Q}{\mathrm{Q}}
\newcommand{\C}{\mathrm{C}}
\newcommand{\OPT}{\mathrm{OPT}}
\newcommand{\bulkdeflate}{\mbox{bulk\_deflate}}
\newcommand{\CRC}{\mbox{CRC-32}}

\newcommand{\yes}{\cellcolor{YellowGreen}\checkmark}
\newcommand{\no}{\cellcolor{Bittersweet}\ding{55}}
\newcommand{\maybe}[1]{\cellcolor{GreenYellow}#1}

\begin{document}

\date{}

\title{\Large \bf A better zip bomb}

\author{
% ANON
% {\rm David Fifield}
}

\maketitle

\begin{abstract}
We show how to construct a
\emph{non-recursive} zip bomb
that achieves a high compression ratio by
overlapping files inside the zip container.
``Non-recursive'' means that it does not rely on
a decompressor's recursively unpacking zip files nested within zip files:
it expands fully after a single round of decompression.
The output size increases quadratically in the input size,
reaching a compression ratio of over 28~million
($\SI{10}{\MB} \rightarrow \SI{281}{\TB}$)
at the limits of the zip format.
Even greater expansion is possible using
64-bit extensions.
The construction uses only the most common compression algorithm, DEFLATE,
and is compatible with most zip implementations.
\end{abstract}


\section{Introduction}
\label{sec:intro}

Compression bombs that use the zip format
must cope with the fact that DEFLATE,
the only compression algorithm universally supported by zip parsers,
cannot achieve a compression ratio greater than
\num{1032}~\cite{zlib_tech}.
For this reason, zip bombs typically rely on recursive decompression,
nesting zip files within zip files to get an extra factor of 1032 with each layer.
But the trick only works on parsers that
unzip recursively, and most do not.
The best-known zip bomb, 42.zip~\cite{42.zip},
expands to a formidable \SI{4.5}{\PB}
if all six of its layers are recursively unzipped,
but a measly \SI{0.6}{\MB} at the top layer.
Zip quines, like those of
Ellingsen~\cite{ellingsen}
and Cox~\cite{cox},
which contain a copy of themselves
and thus expand infinitely if recursively unzipped,
are likewise perfectly safe to unzip once.

This article shows how to construct a non-recursive zip bomb
whose compression ratio surpasses the DEFLATE limit of 1032.
It works by overlapping files inside the zip container,
in order to include a ``kernel'' of highly compressed data
in multiple files, without making multiple copies of it.
The zip bomb's output size grows quadratically in the input size; i.e.,
the compression ratio gets better as the input file gets bigger.
The construction depends on specific features of both zip and DEFLATE---it
is not portable to other container formats or compression algorithms.
It is compatible with most zip parsers,
the exceptions being ``streaming'' parsers that
parse in one pass without first consulting the zip file's central directory.
The zip bomb construction tries to balance
two competing goals:
\begin{itemize}
\item
Maximize the compression ratio.
We define the compression ratio as the the sum of the sizes
of all the files contained the in the zip file,
divided by the size of the zip file itself.
It does not count filenames or other filesystem metadata,
only contents.
\item
Be compatible.
Zip is a tricky format and parsers differ, especially
around edge cases and optional features.
Avoid taking advantage of tricks that only work with certain parsers.
We will remark on ways to increase the efficiency of the zip bomb
that come with some loss of compatibility.
\end{itemize}


\section{Structure of a zip file}
\label{sec:zipstructure}

A~zip file consists of
a \emph{central directory} which references
\emph{files}.
Refer to \autoref{fig:normal}.

The central directory is at the end of the zip file.
It is a list of \emph{central directory headers}.
Each central directory header contains metadata for a single file,
like its filename and \CRC\ checksum,
and a backwards pointer to the file's local file header.
A~central directory header is 46~bytes long,
plus the length of the filename.

A~file consists of a \emph{local file header}
followed by compressed \emph{file data}.
The local file header is 30~bytes long,
plus the length of the filename.
It contains a redundant copy
of the metadata from the central directory header,
and the compressed and uncompressed sizes of the file data
which follows.
Zip is a container format, not a compression algorithm.
Each file's data is compressed by itself,
without reference to any other file,
using an external compression algorithm---usually DEFLATE~\cite{rfc1951}.

This description of the zip format omits many details that
are not needed to understand the construction of the zip bomb.
For full information,
refer to the file format specification~\cite{appnote},
particularly Section~4.3.

\begin{figure*}
\includegraphics{figures/normal}
\caption{
A normal zip file
(\autoref{sec:zipstructure}).
}
\label{fig:normal}
\end{figure*}


\section{The first insight: overlapping files}
\label{sec:overlap}

By compressing a long string of repeated bytes,
we can produce a \emph{kernel}
of highly compressed data.
By itself, the kernel's compression ratio cannot
exceed the DEFLATE limit of \num{1032},
so we want a way to reuse the kernel in many files,
without having to make a separate copy of it in each file.
We can do it by overlapping files:
making many central directory headers point to
a single file whose data is the kernel.
See \autoref{fig:overlap}.

\begin{figure*}
\includegraphics{figures/overlap}
\caption{
Full-overlap zip bomb construction
(\autoref{sec:overlap}).
This construction has problems with compatibility,
because filenames do not agree between the
central directory headers and the local file headers.
The ``kernel'' is a block of highly compressed data,
reused in every file.
}
\label{fig:overlap}
\end{figure*}

Let's look at an example to see how this construction affects the compression ratio.
Suppose the kernel is \SI{1000}{bytes} and
decompresses to \SI{1}{\MB}.
Then the first \SI{1}{\MB} of output ``costs''
\SI{1078}{bytes} of input:
\SI{31}{bytes} for a local file header (including a 1-byte filename),
\SI{47}{bytes} for a central directory header (including a 1-byte filename), and
\SI{1000}{bytes} for the kernel itself.
But every \SI{1}{\MB} of output
after the first costs only \SI{47}{bytes}---we don't need another local file header or copy of the kernel,
only an additional central directory header.
So while the first copy of the kernel has a compression ratio of
$\num{1000000}/\num{1078}\approx \num{928}$,
each additional copy pulls the ratio closer to
$\num{1000000}/\num{47}\approx \num{21277}$.
A~bigger kernel raises the ceiling.

The problem with this idea is a lack of compatibility.
The file metadata---specifically the filename---doesn't match
between the central directory header and local file header,
and some parsers balk at that.
See \autoref{tab:compatibility}.
Info-ZIP UnZip~\cite{infozip-unzip}
(the standard Unix \texttt{unzip} program)
extracts the files, but with warnings:

{\small
\begin{Verbatim}[commandchars=\\\{\}]
$ \textbf{unzip overlap.zip}
  inflating: A
B:  mismatching "local" filename (A),
         continuing with "central" filename version
  inflating: B
\textit{...}
\end{Verbatim}
}

\noindent
And the Python zipfile module~\cite{python-zipfile}
\href{https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L1486-L1489}{throws an exception}
when filenames don't match:

{\small
\begin{Verbatim}[commandchars=\\\{\}]
$ \textbf{python3 -m zipfile -e overlap.zip .}
Traceback (most recent call last):
\textit{...}
__main__.BadZipFile: File name in directory 'B' \textbackslash
and header b'A' differ.
\end{Verbatim}
}

Next we will see how to modify this construction
for filename consistency,
while still retaining most of the advantage
of overlapping files.

% If you are targeting a specific zip parser that you know
% does not check for filename consistency,
% this construction is a good one.
% It grows faster (as a function of the input size)
% than the construction of the next section,
% which has better compatibility
% because it uses separate local file headers.


\section{The second insight:\\quoting local file headers}
\label{sec:quote}

We need to somehow separate the local file headers for each file,
while still reusing a single kernel.
We'll use a feature of DEFLATE, non-compressed blocks,
to ``quote'' local file headers that occur later in the file
so that they appear to be part of the same DEFLATE stream
that terminates in the kernel.
Every local file header,
except the first,
will be interpreted two ways:
as code (part of the structure of the zip file format)
and as data (part of the output file data).

A~DEFLATE stream is a sequence of
blocks~\cite[\S 3.2.3]{rfc1951},
where each block can be compressed or non-compressed.
Compressed blocks are what we usually think of;
for example the kernel is one big compressed block.
But there are also non-compressed blocks,
which start with a
5-byte header~\cite[\S 3.2.4]{rfc1951}
that means simply, ``output the next $n$ bytes verbatim.''
Decompressing a non-compressed block means only stripping the 5-byte header.
Compressed and non-compressed blocks may be intermixed freely
in a DEFLATE stream.
The output is the concatenation of
decompressing all the blocks in order.

It is easiest to understand the construction from the inside out,
starting with the last file and working backwards to the first.
Refer to \autoref{fig:quote}.
Start by inserting the kernel, which will form the end of file data for every file.
Prepend a local file header $\LFH_N$
and add a central directory header $\CDH_N$ that points to it.
Set the ``compressed size'' metadata field in $\LFH_N$ and $\CDH_N$ to the compressed size of the kernel.
Now, insert before $\LFH_N$ a 5-byte non-compressed block header (colored green in the diagram)
whose length field is equal to the size of $\LFH_N$.
For the second time,
prepend a local file header $\LFH_{N-1}$
and add a central directory header $\CDH_{N-1}$ that points to it.
Set the ``compressed size'' metadata field in both headers to the compressed size of the kernel,
\emph{plus} the size of the non-compressed block header (\SI{5}{bytes}),
\emph{plus} the size of $\LFH_N$.

\begin{figure*}
\includegraphics{figures/quote}
\caption{
Quoted-overlap zip file construction
(\autoref{sec:quote}).
Each file contains the local file headers of all the files which follow it,
as well as the kernel.
The green parts stand for DEFLATE non-compressed blocks.
}
\label{fig:quote}
\end{figure*}

At this point the zip file contains two files.
Let's walk through what a zip parser would see while parsing it.
Supposed the compressed size of the kernel is \SI{1000}{bytes}
and the size of $\LFH_N$ is \SI{31}{bytes}.
We start at $\CDH_{N-1}$
and follow the pointer to $\LFH_{N-1}$.
The first file's filename is ``Y'' and
the compressed size of its file data is \SI{1036}{bytes}.
Interpreting the following \SI{1036}{bytes} as a DEFLATE stream,
we first encounter the 5-byte header of a non-compressed block
that says to copy the next \SI{31}{bytes}.
We write the next \SI{31}{bytes},
which happen to be $\LFH_N$,
as output to the file ``Y''.
Moving on in the DEFLATE stream, we find a compressed block (the kernel),
which we decompress to file ``Y''.
Now we have reached the end of the compressed data and are done with file ``Y''.
Proceeding to the next file, we follow the pointer from $\CDH_N$
to $\LFH_N$ and find a file with filename ``Z''
and compressed size \SI{1000}{bytes}.
Interpreting those \SI{1000}{bytes} as a DEFLATE stream,
we immediately encounter a compressed block (the kernel again)
and decompress it to the file ``Z''.
Now we have reached the end of the final file and are done.
The output file ``Z'' contains the decompressed kernel;
the output file ``Y'' is be the same, except additionally prefixed by
$\LFH_N$, \SI{31}{bytes} copied literally from the zip file.

The zip file is constructed by repeating the quoting procedure.
Each new file adds a central directory header,
a local file header,
and a non-compressed block to quote the next local file header.
Compressed file data is generally a chain of DEFLATE non-compressed blocks
(the quoted local file headers)
followed by the compressed kernel.
Each byte in the kernel contributes about
$\num{1032}N$ to the output size,
because it is part of all $N$ files.
The output files are not all the same size:
those that appear earlier in the zip file
are larger than those that appear later,
because they contain more local file headers.
The contents of the output files are nonsense,
but no one said they had to make sense.

This quoted-overlap construction has better compatibility
than the full-overlap construction of \autoref{sec:overlap},
but the compatibility comes at the expense of the compression ratio.
There, each added file cost only a central directory header;
but here, it costs a central directory header,
a local file header,
and another \SI{5}{bytes} for the quoting header.


\section{Optimization}
\label{sec:optimization}

Now that we have the basic zip bomb construction,
we will try to make it as efficient as possible.
We want to answer two questions:

\begin{itemize}
\item For a given zip file size, what's the maximum compression ratio?
\item What's the maximum compression ratio, given the limits of the zip format?
\end{itemize}

\subsection{Kernel compression}
\label{sec:bulkdeflate}

It is worthwhile to compress the kernel as densely as possible,
because every decompressed byte gets magnified by a factor of $N$.
To that end, we use a custom DEFLATE compressor
called \bulkdeflate,
specialized for compressing
a string of repeated bytes.

%          engine compressed_size max_uncompressed_size
% 1: bulk_deflate           21090              21749401
% 2:         zlib           21090              21723602
% 3:       zopfli           21090              21734018

All decent DEFLATE compressors will approach a compression ratio of \num{1032}
when given an infinite stream of repeating bytes,
but we care more about specific finite sizes
than asymptotics.
\autoref{fig:max-uncompressed-size} shows the
maximum amount of output
that can result from uncompressing a DEFLATE stream of a given size,
for \bulkdeflate\ and other implementations.
\bulkdeflate\ compresses more data
into the same space than the general-purpose compressors:
about \SI{26}{\kB} more than zlib and Info-ZIP,
and about \SI{15}{\kB} more than Zopfli~\cite{zopfli},
a compressor that trades compression speed for density.

\begin{figure}
\includegraphics{data/max_uncompressed_size}
\caption{
Comparison of DEFLATE compressors
on a string of repeated bytes.
}
\label{fig:max-uncompressed-size}
\end{figure}

The price of \bulkdeflate's high compression ratio is a lack of generality.
\bulkdeflate\ can only compress strings of a single repeate byte,
and only those of specific lengths,
namely $517 + 258 k$ for integer $k \ge 0$.
Besides compressing densely, \bulkdeflate\ is fast,
doing essentially constant work regardless of the input size
(aside from the $O(n)$ work of actually writing out the compressed string).

\subsection{Filenames}
\label{sec:filenames}

For our purposes, filenames are mostly dead weight.
While filenames do contribute something to the output size
by virtue of being part of quoted local file headers,
a byte in a filename does not contribute nearly as much to the output size
as does a byte in the kernel.
So we want filenames to be as short as possible,
while keeping them all distinct,
and subject to compatibility considerations.

The first compatibility consideration is filename encoding.
The zip format specification states that filenames
are to be interpreted as CP~437,
or \mbox{UTF-8} if a certain flag bit is set~\cite[Appendix~D]{appnote}.
But this is a major point of incompatibility
between zip parsers,
which may interpret filenames as being in
some fixed or locale-specific encoding, or ignore the \mbox{UTF-8} bit, for example.
So for compatibility, it's best to stick to characters
that have the same encoding in both
CP~437 and \mbox{UTF-8},
namely, the \num{95} printable characters of \mbox{US-ASCII}.
% https://bugs.python.org/issue10614
% https://bugs.python.org/issue10972
% https://github.com/thejoshwolfe/yauzl/issues/84

Another compatibility consideration is filesystem restrictions.
Some filesystems are case-insensitive, so ``a'' and ``A'' do not count as distinct names.
Common filesystems like FAT32 prohibit certain characters like
`*' and `?'~\cite[\S Limits]{wiki-fs}.

As a safe compromise between all these considerations,
our zip bomb will use filenames consisting of characters
drawn from a 36-character alphabet
that does not
rely on case distinctions
or use special characters:

\begin{center}
\setlength{\tabcolsep}{2pt}
\begin{tabular}{cccccccccccccccccc}
0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & A & B & C & D & E & F & G & H \\
I & J & K & L & M & N & O & P & Q & R & S & T & U & V & W & X & Y & Z
\end{tabular}
\end{center}

\noindent
Filenames are generated in the obvious way,
cycling each position through the possible characters
and adding a position on overflow:

\begin{center}
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rrrrrl}
``\mbox{0}'', &
``\mbox{1}'', &
``\mbox{2}'', &
\ldots, &
``\mbox{Z}'',
\\
``\mbox{00}'', &
``\mbox{01}'', &
``\mbox{02}'', &
\ldots, &
``\mbox{0Z}'',
\\
\ldots,
\\
``\mbox{Z0}'', &
``\mbox{Z1}'', &
``\mbox{Z2}'', &
\ldots, &
``\mbox{ZZ}'',
\\
``\mbox{000}'', &
``\mbox{001}'', &
``\mbox{002}'', &
\ldots
\end{tabular}
\end{center}

\noindent
There are $36$ filenames of length~\num{1},
$36^2$ filenames of length~\num{2}, and so on.
Using this scheme, four character positions are enough for
\num{1727604} filenames.

% The length of the $n$\/th filename is
% $\lfloor \log_{36}((n + 1) / \frac{36}{35})\rfloor + 1$.
% The sum of the lengths of the first $n$ filenames is
% $dn - ((36^d - 1) \frac{36}{35^2} - \frac{d}{35})$,
% where $d = \lfloor \log_{36}(n / \frac{36}{35})\rfloor$.
% https://oeis.org/A014824

Given that the $N$ filenames in the zip file
are generally not all of the same length,
how should we order them,
shortest to longest or longest to shortest?
A~little reflection shows that it is better to
put the longest names last, because those names are the most quoted.
Ordering filenames longest last
adds over \SI{900}{\MB} of output
in the ``large'' zip bomb we will see in \autoref{sec:allocation},
compared to ordering them longest first.
It is only a minor optimization, though,
as those \SI{900}{\MB} comprise only \num{0.0003}\%
of the total output size.

% $ unzip -l zblg.zip | tail -n 1
% 281395456244934                     65534 files
% $ unzip -l zblg.rev.zip | tail -n 1
% 281394526372494                     65534 files
% $ python
% >>> 281395456244934 - 281394526372494
% 929872440
% >>> 929872440 / 281395456244934. * 100
% 0.00033045041039703735

\subsection{Kernel size}
\label{sec:allocation}

The quoted-overlap construction
allows us to place a compressed kernel of data,
and then cheaply copy it many times.
For a given zip file size~$X$,
how much space should we devote to storing the kernel,
and how much to making copies?

To find the optimum balance,
we only have to optimize the single variable $N$,
the number of files in the zip file.
Every value of $N$ requires
a certain amount of overhead for
central directory headers,
local file headers,
quoting block headers, and filenames.
All the remaining space can be taken up by the kernel.
Because $N$ has to be an integer,
and there are only so many files you can fit
before the kernel size drops to zero,
it suffices to test every possible value of $N$
and select the one that yields the most output.

Applying the optimization procedure to $X = \num{42374}$,
the size of 42.zip,
finds a maximum at $N = 250$.
Those \num{250} files require \SI{21195}{bytes} of overhead,
leaving \SI{21179}{bytes} bytes for the kernel.
The kernel, by itself, decompresses to \SI{21841249}{bytes}
(a~ratio of \num{1031.3}).
The \num{250} copies of the decompressed kernel,
plus the little bit extra that comes from the quoted local file headers,
produces an overall unzipped output of
\SI{5461307620}{bytes}
and a~compression ratio of 128~thousand.
See the row marked ``small'' in \autoref{tab:comparison}.

Optimization produced an almost an even split
of the available space
between the kernel and the file headers.
It is not a coincidence.
Let's look at a simplified model of the quoted-overlap construction.
In the simplified model,
we ignore filenames,
as well as the slight increase in output file size
due to quoting local file headers.
Analysis of the simplified model will show that the optimum
split between kernel and file headers is approximately even,
and that the output size grows quadratically in the input size
when space is allocated optimally.

Define some constants and variables:

\begin{align*}
X & & & \mbox{zip file size (take as fixed)} \\
N & & & \mbox{number of files in the zip file} \\
\CDH &= \num{46} & & \mbox{size of a central directory header} \\
\LFH &= \num{30} & & \mbox{size of a local file header} \\
\Q   &=  \num{5} & & \mbox{size of a quoting block header} \\
\C   &\approx \num{1032} & & \mbox{compression ratio of the kernel}
\end{align*}

% JACAL session to do the algebra and calculus:
% 
% # S_X(N)
% e1 : C * N * (X - (N * (LFH + CDH) + (N - 1) * Q)));
%                                                   ^
% 
%                        2             2
% e1: (- C CDH - C LFH) N  + (C N - C N ) Q + C N X
% 
% # S_X(N) as a polynomial in N
% e2 : coeffs(e1, N);
% 
% e2: [0, C Q + C X, - C CDH - C LFH - C Q]
% 
% # S'_X(N)
% e3 : diff(e1, N);
% 
% e3: (- 2 C CDH - 2 C LFH) N + (C - 2 C N) Q + C X
% 
% # S'_X(N) as a polynomial in N
% e4 : coeffs(e3, N);
% 
% e4: [C Q + C X, - 2 C CDH - 2 C LFH - 2 C Q]
% 
% # Solve S'_X(N) = 0. e5 == N_OPT
% e5 : suchthat(N, e3);
% 
%            Q + X
% e5: - - - - - - - - - -
%     2 CDH + 2 LFH + 2 Q
% 
% # H(N_OPT)
% e6 : e5 * (LFH + CDH) + (e5 - 1) * Q;
% 
%     - Q + X
% e6: - - - -
%        2
% 
% # S_X(N_OPT)
% e7 : -C * (CDH + LFH + Q) * e5^2 + C * (Q + X) * e5;
% 
%        2                2
%     C Q  + 2 C Q X + C X
% e7: - - - - - - - - - - -
%      4 CDH + 4 LFH + 4 Q

Let $H(N)$
be the amount of header overhead required for $N$ files.
Refer to \autoref{fig:quote}
to understand where this formula comes from.

\begin{align*}
H(N) &= N\cdot(\CDH + \LFH) + (N - 1)\cdot\Q
\end{align*}

The space remaining for the kernel is
$X - H(N)$.
The total unzipped size
$S_X(N)$
is the size of $N$ copies
of the kernel,
decompressed at ratio~$\C$.
(In this simplified model we ignore
the minor additional expansion from quoted local file headers.)

\begin{align*}
S_X(N) &= (X - H(N)) \, \C \, N \\
       &= (X - (N \cdot (\CDH + \LFH) + (N - 1)\cdot\Q)) \, \C \, N \\
       &= -(\CDH + \LFH + \Q) \, \C \, N^2 + (X + \Q) \, \C \, N
\end{align*}

$S_X(N)$
is a polynomial in $N$,
so its maximum must be at a place where its derivative
$S'_X(N)$
is zero.
Taking the derivative and finding the zero gives us
$N_\OPT$,
the optimal number of files.

\begin{align*}
S'_X(N_\OPT) &= - 2 (\CDH + \LFH + \Q) \, C \, N_\OPT + (X + \Q) \, \C \\
           0 &= - 2 (\CDH + \LFH + \Q) \, C \, N_\OPT + (X + \Q) \, \C \\
     N_\OPT  &= \frac{X + \Q}{2 (\CDH + \LFH + \Q)}
\end{align*}

$H(N_\OPT)$
gives the optimal amount of space to allocate for file headers.
It is independent of $\CDH$, $\LFH$, and $\C$,
and close to $X/2$.

\begin{align*}
H(N_\OPT) &= N_\OPT\cdot(\CDH + \LFH) + (N_\OPT - 1)\cdot\Q \\
          &= \frac{X - \Q}{2}
\end{align*}

$S_X(N_\OPT)$
is the total unzipped size
when the allocation is optimal.
From this we see that the output size grows quadratically
in the input size.

\begin{align}
\label{eq:opt}
S_X(N_\OPT) &= \frac{(X + \Q)^2 \, \C}{4(\CDH + \LFH + \Q)}
\end{align}

\begin{quote}
\sl
Note to reviewers:
we would appreciate advice
on adapting the simplified model
so that $S_X(N_\OPT)$ is
an actual lower bound on the zip bomb's growth.
The problem with the analysis above is that while it slightly underestimates
the output size by ignoring the contribution of quoted local file headers,
it also overestimates the size of the kernel
by giving the kernel the bytes that would be required to store filenames.
To be precise, $H(N)$ needs an additional term
that upper-bounds the space required for $N$ filenames.
The bounds we tried led to messy and unenlightening formulas.
If it helps, the length of the $n$\/th filename is
$\lfloor \log_{36}((n + 1) / \frac{36}{35})\rfloor + 1 =
\lfloor \log_{36}(n + 1) + \log_{36}(35)\rfloor = O(\log n)$.
If we let $d$ be the length of the longest filename,
the sum of the lengths of the first $n$ filenames is
$d\cdot(n+1) - ((36^d - 1) \frac{36}{35^2} - \frac{d}{35}) = O(n\log n)$.
This comes from the observation that all filenames have length $\ge 1$,
all but $36$ have length $\ge 2$,
all but $36+36^2$ have length $\ge 3$, and in general
all but $36+36^2+\cdots+36^{i-1} = \frac{36^i-1}{35}-1$ have length $\ge i$,
for $1 \le i \le d$.
Therefore the sum of lengths is \\
$\phantom{=}\sum_{i=1}^d n - (\frac{36^i-1}{35}-1) \\
= d\cdot(n+1) - \sum_{i=1}^d \frac{36^i-1}{35} \\
= d\cdot(n+1) - ((36^d - 1)\frac{36}{35^2} - \frac{d}{35})$,\\
where the last equality comes from adapting a formula found in
\url{https://oeis.org/A014824}.
See the comment on \texttt{sum\_filename\_lengths}
in \mbox{optimize.R} in the source code.
\end{quote}

As we make the zip file larger and larger,
eventually we run into the limits of the zip format.
A~zip file can contain at most $2^{16}-1$ files
and each file can have an uncompressed size of at most $2^{32}-1$ bytes.
Worse than that:
some implementations (see \autoref{tab:compatibility})
take the maximum possible values
as an indicator of the presence of 64-bit extensions (\autoref{sec:zip64}),
so our limits are actually $2^{16}-2$ and $2^{32}-2$.
% https://github.com/golang/go/commit/4aedbf5be4631693f774063410707ef467ca78e7
% https://github.com/golang/go/commit/b6c5edae7c0e9dd6d12dbb8f1c9638dea45f9464
It happens that the first limit we hit is the one on uncompressed file size.
At a zip file size of \SI{8319377}{bytes},
naive optimization would give us a file count of \num{47837}
and a largest file with an impossible uncompressed size of
$2^{32}+311$ bytes.
% $compressed_size
% [1] 4160277
% 
% $num_files
% [1] 47837
% 
% [1] "zipped size" "8319377"
% [1] "unzipped size"   "205420672417247"
% [1] 4294967607

Accepting that we cannot increase $N$ nor the size of the kernel without bound,
we would like find the maximum compression ratio achievable
while remaining within the limits of the zip format.
The way to proceed is to make the kernel as large as possible,
and have the maximum number of files.
Even though we can no longer maintain an even split
between the kernel and file headers,
each added file \emph{does} increase the compression ratio---just
not as fast as it would if we were able to keep growing the kernel at the same time.
In fact, as we add files we will need to \emph{decrease} the size of the kernel
to make room for the maximum file size
that gets slightly larger with each added file.

This plan results in a zip file
that contains $2^{16}-2$ files and a kernel that decompresses
to $2^{32}-\num{2178825}$ bytes.
See the row marked ``large'' in \autoref{tab:comparison}.
The largest file (the first file) uncompresses to
$2^{32} - 56$ bytes.
That is as close as we can get using \bulkdeflate---encoding
the final \SI{54}{bytes} would require more bytes
than they are worth.
The output size of this zip bomb, \SI{281395456244934}{bytes},
is 99.97\% of the theoretical maximum
$(2^{32}-1)\cdot(2^{16}-1)$.
% 65 535 × 0xffffffff = <data value="281470681677825">281 470 681 677 825</data>.
Any major improvements to the compression ratio can only come
from reducing the input size,
not increasing the output size.
% >>> (2**32-1)*65535 - 281399752637796
% 70929040029
% >>> 70929040029. / ((2**32-1)*65535)
% 0.00025199441592352524
% >>> 1 - _
% 0.9997480055840765
% >>> _ * 100
% 99.97480055840765


\section{Efficient \CRC\ computation}
\label{sec:crc32}

The metadata in the central directory header and local file header
includes a \CRC\ checksum
of the uncompressed data.
This poses a problem, because if we calculate the \CRC\ of each file directly,
we will end up doing work proportional to the total <em>unzipped</em> size,
which is large by design (it's a zip bomb, after all).
We would really prefer to only do work proportional to the <em>zipped</em> size—a
fast way to compute checksums doesn't help the compression ratio,
but it is necessary to make generating the zip bomb practical.
We can do it by exploiting the fact that all the files in the zip file
share a common suffix (the uncompressed kernel)
and using properties of \CRC\ to combine computations without redoing work.
The technique is a slight generalization of the
\texttt{crc32\_combine}
function~\cite{crc32combine} in zlib.

You can model \CRC\ as a state machine that updates a 32-bit state register
for each incoming bit.
The basic update operations for a 0 bit and a 1 bit are:
\begin{verbatim}
uint32 crc32_update_0(uint32 state) {
	if (state &amp; 1 == 0) {
		// Shift out the least significant bit.
		state = state &gt;&gt; 1;
	} else {
		// Shift out the least significant bit, then XOR with the CRC-32 constant.
		state = (state &gt;&gt; 1) ^ 0xedb88320;
	}
	return state;
}

uint32 crc32_update_1(uint32 state) {
	// Flip the least significant bit, then proceed as for a 0 bit.
	return crc32_update_0(state ^ 1);
}
\end{verbatim}

The only difference in the case of a 1 bit is that we flip the least significant bit
of the state register before proceeding.
After that, we shift out the least significant bit of the state register,
and if it was a 1, XOR the state with a 32-bit constant
representing the \CRC\ polynomial.

We can rewrite these operations in a way
that makes it clearer that the \CRC\ update functions
can be expressed as matrix multiplications:
\begin{verbatim}
uint32 crc32_update_0(uint32 state) {
	uint32_t new_state = 0;
	for (unsigned int n = 31; n &gt;= 1; n--) {
		// Right-shift the bit at position n into position (n-1).
		new_state ^= ((state&gt;&gt;n) &amp; 1) * (1&lt;&lt;(n-1));
	}
	// If the 0th bit was set, XOR with the CRC-32 constant.
	new_state ^= ((state&gt;&gt;0) &amp; 1) * 0xedb88320;
	return new_state;
}

uint32 crc32_update_1(uint32 state) {
	// Do as for a 0 bit, then XOR with the CRC-32 constant.
	return crc32_update_0(state) ^ 0xedb88320;
}
\end{verbatim}

<p>
If we think of the state register as a being 32-element binary vector,
and XOR as representing addition,
then \texttt{crc32\_update\_0} is the sum
of multiplying each bit in the state vector with another vector.
In other words, \texttt{crc32\_update\_0} is a
linear transformation
that can be represented as multiplication by a $32\times 32$ binary
transformation matrix.
The columns of the transformation matrix are the vectors with
which each bit of the state vector is multiplied.
</p>

<p>
Furthermore, \texttt{crc32\_update\_1} is just the output of
\texttt{crc32\_update\_0} plus a constant
(with XOR representing addition).
That means \texttt{crc32\_update\_1} is an
affine transformation:
a matrix multiplication followed by an addition (translation).
We can represent an affine transformation as a single
transformation matrix (no separate translation)
if we enlarge the matrix dimensions to $33\times 33$
and add an extra element to the state vector which is always 1.
This representation is called
homogeneous coordinates.
After applying the transformation,
we simply strip the extra coordinate to recover the 32-bit state.
</p>

<caption><var>M</var><sub>0</sub>, the $33\times 33$ affine transformation matrix for \CRC\ of a 0 bit.</caption>
\[
\setcounter{MaxMatrixCols}{33}
\begin{smallmatrix}
0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1
\end{smallmatrix}
\]

<caption><var>M</var><sub>1</sub>, the $33\times 33$ affine transformation matrix for \CRC\ of a 1 bit.</caption>
\[
\setcounter{MaxMatrixCols}{33}
\begin{smallmatrix}
0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1 \\
0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1 \\
1&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1 \\
0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0&1 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&1 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&1 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&1 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0&1 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&0&1 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0&1 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&0&0 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&0&1 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1&1 \\
1&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1 \\
0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&1
\end{smallmatrix}
\]

<p>
So both operations \texttt{crc32\_update\_0} and \texttt{crc32\_update\_1}
can be represented by a $33\times 33$ transformation matrix.
The two matrices <var>M</var><sub>0</sub> and <var>M</var><sub>1</sub> are shown.
Column vectors are stored with the most significant bit at the bottom:
reading the first column from bottom to top, you see
the \CRC\ constant 0xedb88320 = 11101101101110001000001100100000<sub>2</sub>.
The two matrices differ only in the last column, which represents the amount of translation:
in <var>M</var><sub>0</sub> it is zero and
in <var>M</var><sub>1</sub> it is 0xedb88320, the \CRC\ polynomial constant.
The 1's just above the diagonal represent the
\texttt{state~>>~1} operation.

<p>
The benefit of representing \CRC\ as matrices is that matrices compose.
Suppose we want to represent the static change caused by processing
the ASCII character <code>a</code>, whose binary representation is
01100001<sub>2</sub>.
We can represent the state change of those 8 bits in a single transformation matrix:
</p>
<figure>
<table class=eqnarray>
<tr>
% <td><var>M</var><sub><code>a</code></sub></td><td> = <var>M</var><sub>0</sub> × <var>M</var><sub>1</sub> × <var>M</var><sub>1</sub> × <var>M</var><sub>0</sub> × <var>M</var><sub>0</sub> × <var>M</var><sub>0</sub> × <var>M</var><sub>0</sub> × <var>M</var><sub>1</sub></td>
</tr>
</table>
</figure>
<p>
Now we can compute the state change of a repeated string of <code>a</code>
my multiplying many copies of <var>M</var><sub><code>a</code></sub> together—matrix exponentiation.
There's an efficient way to do matrix exponentiation
called the square-and-multiply algorithm,
which allows us to compute <var>M</var><sup><var>n</var></sup>
in only about log<sub>2</sub> <var>n</var> steps.
For example, to represent the \CRC\ state change from processing a
string of 9 <code>a</code>'s:
</p>
<figure>
<table class=eqnarray>
<tr>
% <td>(<var>M</var><sub><code>a</code></sub>)<sup>9</sup></td><td> = <var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub></td>
</tr>
<tr>
% <td></td><td> = (<var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub>)<sup>2</sup> × <var>M</var><sub><code>a</code></sub></td>
</tr>
<tr>
% <td></td><td> = ((<var>M</var><sub><code>a</code></sub> × <var>M</var><sub><code>a</code></sub>)<sup>2</sup>)<sup>2</sup> × <var>M</var><sub><code>a</code></sub></td>
</tr>
<tr>
% <td></td><td> = (((<var>M</var><sub><code>a</code></sub>)<sup>2</sup>)<sup>2</sup>)<sup>2</sup> × <var>M</var><sub><code>a</code></sub></td>
</tr>
</table>
</figure>

<p>
There's one more minor complication in \CRC\ computation.
The state register is not initialized to 0, but to 0xffffffff (preconditioning)
And at the end of the input, the state register is XORed with 0xffffffff
before being returned (postconditioning).
We'll model this as additional steps to do before and after
the matrix multiplication.
Similarly we'll take care of adding and removing the extra element
for homogeneous coordinates and wrap it all up in an \texttt{apply\_matrix}
operation:
</p>
<figure>
<table class=eqnarray>
<tr>
% <td><code>apply_matrix</code>(<var>M</var>, <var><b>v</b></var>)</td><td> = ((<var>M</var> × ((<var><b>v</b></var> ^ 0xffffffff) | (1&lt;&lt;32))) &amp; 0xffffffff) ^ 0xffffffff</td>
</tr>
</table>
</figure>

<p>
Now we are ready to compute the \CRC\ checksums for the files in the zip file.
Use the square-and-multiply method we can compute <var>M</var><sub>kernel</sub>,
the \CRC\ matrix for the kernel, which is a long stream of repeated bytes.
Initialize <var>M</var> := <var>M</var><sub>kernel</sub>.
Now \texttt{apply\_matrix}(<var>M</var>, 0)
yields the checksum for the kernel,
which is also the checksum of the final file, file <var>N</var>.
Store this checksum in CDH<sub><var>N</var></sub> and LFH<sub><var>N</var></sub>,
the central directory header and local file header of file <var>N</var>.
Now we work backwards.
Compute <var>M</var><sub>LFH<sub><var>N-1</var></sub></sub>,
the matrix for the bytes of the local file header of file <var>N - 1</var>.
% Now update <var>M</var> := <var>M</var> × <var>M</var><sub>LFH<sub><var>N-1</var></sub></sub>;
this has the effect of adding a prefix of LFH<sub><var>N-1</var></sub>
to the \CRC\ change represented by <var>M</var>.
Now \texttt{apply\_matrix}(<var>M</var>, 0)
yields the checksum for file <var>N - 1</var>,
to be stored in
CDH<sub><var>N-1</var></sub> and LFH<sub><var>N-1</var></sub>.
Repeat this process, accumulating prefixes into <var>M</var>,
until you have processed all the files.
</p>



\section{Extension: Zip64}
\label{sec:zip64}

\autoref{eq:opt}

x

Somewhat related, Plötz et~al.~\cite[\S 4]{SAR-PR-2006-04}
used overlapping files to achieve
almost complete replication of the zip file itself.

\begin{table*}
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{rccccccc}
&
\thead{Info-ZIP\\UnZip~6.0~\cite{infozip-unzip}} &
\thead{Python~3.7\\zipfile~\cite{python-zipfile}} &
\thead{Go~1.12\\archive/zip~\cite{golang-archivezip}} &
\thead{yauzl~2.10.0~\cite{yauzl}\\(Node.js)} &
\thead{Nail~\cite{186219}\\examples/zip~\cite{nail-zip}} &
\thead{Android~9.0.0~r1\\libziparchive~\cite{android-libziparchive}} &
\thead{sunzip~0.4~\cite{sunzip}\\(streaming)}
\\
\thead[r]{DEFLATE} &
\yes &
\href{https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L57}{\yes} &
\href{https://github.com/golang/go/blob/go1.12/src/archive/zip/struct.go#L31}{\yes} &
\href{https://github.com/thejoshwolfe/yauzl/blob/2.10.0/index.js#L520-L521}{\yes} &
\href{https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.c#L63}{\yes} &
\href{https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#1059}{\yes} &
\href{https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1256}{\yes}
\\
\thead[r]{Zip64} &
\href{http://infozip.sourceforge.net/UnZip.html#Release}{\yes} &
\href{https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L186}{\yes} &
\href{https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L519}{\yes} &
\href{https://github.com/thejoshwolfe/yauzl/tree/2.10.0#limitted-zip64-support}{\yes} &
\href{https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.c#L103-L125}{\no} &
\href{https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#168}{\no} &
\href{https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L922}{\yes}
\\
\thead[r]{bzip2} &
\href{http://infozip.sourceforge.net/UnZip.html#Release}{\yes} &
\href{https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L58}{\yes} &
\href{https://github.com/golang/go/blob/go1.12/src/archive/zip/struct.go#L28-L32}{\no} &
\href{https://github.com/thejoshwolfe/yauzl/blob/2.10.0/index.js#L517-L525}{\no} &
\href{https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.c#L86}{\no} &
\href{https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#1061}{\no} &
\href{https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1256}{\yes}
\\
\thead[r]{tolerates mismatched filenames} &
\maybe{warns} &
\href{https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L1486-L1489}{\no} &
\href{https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L244}{\yes} &
\href{https://github.com/thejoshwolfe/yauzl/tree/2.10.0#local-file-headers-are-ignored}{\yes} &
\href{https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L49}{\yes} &
\href{https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#594}{\no} &
\href{https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1268-L1269}{\yes}
\\
\thead[r]{tolerates incorrect \CRC} &
\maybe{warns} &
\href{https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L893-L894}{\no} &
\href{https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L219-L224}{\maybe{if zero}} &
\href{https://github.com/thejoshwolfe/yauzl/tree/2.10.0#no-crc-32-checking}{\yes} &
\href{https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L41}{\no} &
\href{https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#52}{\yes} &
\href{https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1465-L1469}{\no}
\\
\thead[r]{permits file size of $2^{32}-1$} &
\yes &
\href{https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L1311-L1313}{\yes} &
\href{https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L406-L414}{\yes} &
% ANON
\no & % \href{https://github.com/thejoshwolfe/yauzl/issues/109}{\no} &
\href{https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L59}{\yes} &
\href{https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive_common.h#95}{\yes} &
\href{https://github.com/madler/sunzip/blob/master/sunzip.c#L1275-L1277}{\yes}
\\
\thead[r]{permits file count of $2^{16}-1$} &
\yes &
\href{https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L258-L259}{\yes} &
\href{https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L502-L511}{\yes} &
% ANON
\no & % \href{https://github.com/thejoshwolfe/yauzl/issues/108}{\no} &
\href{https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L79}{\yes} &
\href{https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive_common.h#51}{\yes} &
\href{https://github.com/madler/sunzip/blob/master/sunzip.c#L1139}{\yes}
\\
\noalign{\vspace{0.5em}}
\thead[r]{parses full overlap\\(\autoref{sec:overlap})} &
\maybe{warns} &
\no &
\yes &
\yes &
\yes &
\no &
\no
\\
\thead[r]{parses quoted overlap\\(\autoref{sec:quote})} &
\yes &
\yes &
\yes &
\yes &
\yes &
\yes &
\no
\\
\thead[r]{parses quoted overlap Zip64\\(\autoref{sec:zip64})} &
\yes &
\yes &
\yes &
\yes &
\no &
\no &
\no
\end{tabular}
\caption{
Compatibility of selected zip parsers with various zip features,
edge cases,
and zip bomb constructions.
For best compatibility,
use DEFLATE compression without Zip64,
match names in central directory headers and local file headers,
compute correct CRCs,
and avoid the maximum values of 32-bit and 16-bit fields.
}
\label{tab:compatibility}
\end{table*}

\begin{table*}
\centering
\begin{threeparttable}
\begin{tabular}{rr|rr@{}l|rr@{}l}
&
&
\multicolumn{3}{c|}{\textbf{non-recursive}} &
\multicolumn{3}{c}{\textbf{recursive}}
\\
&
zipped size &
unzipped size &
\multicolumn{2}{r|}{ratio\phantom{~thousand}} &
unzipped size &
\multicolumn{2}{r}{ratio\phantom{~thousand}}
\\
Cox quine~\cite{cox} &
\num{440} &
\num{440} &
\num{1}&.0 &
$\infty$ &
$\infty$&
\\
Ellingsen quine~\cite{ellingsen} &
\num{28809} &
\num{42569} &
\num{1}&.5 &
$\infty$ &
$\infty$&
\\
42.zip~\cite{42.zip} &
\num{42374}\tnote{*} &
\num{558432} &
\num{13}&.2 &
\num{4507981343026016} &
106&~billion
\\
this technique (small) &
\num{42374} &
\num{5461307620} &
129&~thousand &
\num{5461307620} &
129&~thousand
\\
this technique (large) &
\num{9893525} &
\num{281395456244934} &
28&~million &
\num{281395456244934} &
28&~million
\\
this technique (Zip64) &
\num{45876952} &
\num{4507981427706459} &
98&~million &
\num{4507981427706459} &
98&~million
% \\
% this technique (Zip64) &
% \num{2961656712} &
% \num{18446744085437447493} &
% 6&~billion &
% \num{18446744085437447493} &
% 6&~billion
\end{tabular}
\caption{
Comparison of zip bomb constructions.
}
\label{tab:comparison}
\begin{tablenotes}
\item [*]
There are two versions of 42.zip,
an \href{https://web.archive.org/web/20120222083624/http://www.unforgettable.dk/}{older version} of \num{42374} bytes,
and a \href{https://web.archive.org/web/20120301154142/http://www.unforgettable.dk/}{newer version} of \num{42838} bytes.
The only difference between them is that the newer version has a password.
We use only the older version.
\end{tablenotes}
\end{threeparttable}
\end{table*}

% ANON
% \section*{Acknowledgements}

\section*{Availability}

% TODO: cryptobin

% ANON
% \url{https://www.bamsoftware.com/hacks/zipbomb/}

\bibliographystyle{plain}
\bibliography{zipbomb}

\end{document}
